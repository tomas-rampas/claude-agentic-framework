---
category: quality
priority: high
agents: [test-agent]
description: "Overall testing approach and methodology"
tags: [testing, strategy, methodology, planning]
last_updated: "2025-09-07"
mcp_dependencies: []
---

# Testing Strategy Hook
# Defines comprehensive testing approaches and methodologies

hook_name: testing-strategy
version: "1.0"
trigger: "on_test_planning"

# CORE STRATEGY ACTIONS
actions:
  select_methodology:
    description: "Choose appropriate testing approach"
    required: true
    implementation: |
      - Analyze project context and constraints
      - Evaluate available resources and timeline
      - Consider team expertise and tools
      - Select primary testing methodology
      - Define hybrid approaches if needed
    
  define_priorities:
    description: "Set testing priorities based on risk and impact"
    required: true
    implementation: |
      - Risk-based prioritization
      - Business impact assessment
      - Technical complexity analysis
      - User journey criticality mapping
    
  allocate_resources:
    description: "Plan resource allocation for testing activities"
    required: true
    implementation: |
      - Estimate testing effort
      - Assign team members to testing activities
      - Plan infrastructure and tooling needs
      - Schedule testing phases
    
  schedule_execution:
    description: "Create comprehensive testing schedule"
    required: false
    implementation: |
      - Integrate with development sprints
      - Plan regression testing cycles
      - Schedule performance testing windows
      - Coordinate with deployment schedules

# TESTING METHODOLOGIES
strategies:
  test_pyramid:
    description: "Traditional test pyramid approach"
    principles:
      - "Lots of unit tests (70%)"
      - "Some integration tests (20%)"
      - "Few E2E tests (10%)"
    
    benefits:
      - Fast feedback cycles
      - Lower maintenance costs
      - Better isolation of failures
      - Scalable test suite
    
    implementation:
      unit_tests:
        percentage: 70
        characteristics:
          - Fast execution (< 5ms each)
          - No external dependencies
          - High code coverage
          - Test single units of functionality
        
        tools:
          javascript: ["jest", "mocha", "vitest"]
          python: ["pytest", "unittest", "nose2"]
          go: ["go test", "testify"]
          java: ["junit", "testng"]
      
      integration_tests:
        percentage: 20
        characteristics:
          - Test component interactions
          - Use real databases/services
          - Moderate execution time
          - Test business workflows
        
        types:
          - API integration tests
          - Database integration tests
          - Message queue integration tests
          - Third-party service integration tests
      
      e2e_tests:
        percentage: 10
        characteristics:
          - Test complete user journeys
          - Use production-like environment
          - Slower execution
          - High business value validation
        
        tools:
          web: ["playwright", "cypress", "selenium"]
          mobile: ["appium", "detox", "xcuitest"]
  
  risk_based:
    description: "Risk-based testing prioritization"
    principles:
      - Focus on high-risk, high-impact areas
      - Use risk assessment matrices
      - Adjust testing depth based on risk level
      - Continuously reassess risk profiles
    
    risk_assessment:
      business_impact:
        high:
          - Revenue-generating features
          - User authentication/authorization
          - Payment processing
          - Data security
        
        medium:
          - User experience features
          - Reporting functionality
          - Configuration management
          - Integration points
        
        low:
          - Cosmetic improvements
          - Non-critical notifications
          - Optional features
          - Internal tools
      
      technical_complexity:
        high:
          - New technology integration
          - Complex algorithms
          - Concurrent processing
          - Performance-critical code
        
        medium:
          - Standard CRUD operations
          - Well-known patterns
          - Established frameworks
          - Moderate data processing
        
        low:
          - Simple data display
          - Static content
          - Configuration settings
          - Basic validations
    
    risk_matrix:
      high_impact_high_complexity:
        testing_approach: "Comprehensive testing"
        coverage_target: 95%
        test_types: ["unit", "integration", "e2e", "performance", "security"]
      
      high_impact_low_complexity:
        testing_approach: "Focused testing"
        coverage_target: 85%
        test_types: ["unit", "integration", "e2e"]
      
      low_impact_high_complexity:
        testing_approach: "Technical testing"
        coverage_target: 90%
        test_types: ["unit", "integration", "performance"]
      
      low_impact_low_complexity:
        testing_approach: "Basic testing"
        coverage_target: 70%
        test_types: ["unit"]
  
  exploratory:
    description: "Exploratory testing methodology"
    principles:
      - Simultaneous learning, test design, and execution
      - Investigative approach to testing
      - Human creativity and intuition
      - Unscripted testing sessions
    
    session_structure:
      charter: "Define the scope and mission of testing session"
      time_box: "Fixed time duration (typically 60-120 minutes)"
      notes: "Real-time documentation of findings"
      debrief: "Session summary and follow-up actions"
    
    techniques:
      - boundary_value_exploration
      - error_condition_probing
      - workflow_variation_testing
      - negative_scenario_discovery
    
    artifacts:
      - session_notes
      - bug_reports
      - test_ideas
      - risk_observations
  
  regression_focused:
    description: "Regression testing emphasis"
    principles:
      - Detect unintended changes
      - Maintain existing functionality
      - Automate repetitive testing
      - Prioritize based on change impact
    
    regression_scope:
      full_regression:
        triggers:
          - Major releases
          - Architecture changes
          - Critical bug fixes
        
        coverage: "Complete test suite execution"
        duration: "2-4 hours"
      
      targeted_regression:
        triggers:
          - Minor features
          - Bug fixes
          - Configuration changes
        
        coverage: "Impacted areas + related functionality"
        duration: "30-60 minutes"
      
      smoke_regression:
        triggers:
          - Daily deployments
          - Hotfixes
          - Environment changes
        
        coverage: "Critical path functionality"
        duration: "5-15 minutes"
  
  continuous:
    description: "Continuous testing integration"
    principles:
      - Testing as part of CI/CD pipeline
      - Fast feedback loops
      - Automated test execution
      - Quality gates enforcement
    
    pipeline_integration:
      commit_stage:
        tests: ["unit", "static_analysis", "security_scan"]
        duration_target: "< 10 minutes"
        failure_action: "Block progression"
      
      acceptance_stage:
        tests: ["integration", "contract", "component"]
        duration_target: "< 30 minutes"
        failure_action: "Block deployment"
      
      deployment_stage:
        tests: ["smoke", "health_check", "monitoring"]
        duration_target: "< 5 minutes"
        failure_action: "Rollback deployment"

# TESTING PLANNING FRAMEWORK
planning:
  test_analysis:
    requirements_analysis:
      - functional_requirements_review
      - non_functional_requirements_identification
      - business_rule_extraction
      - acceptance_criteria_validation
    
    risk_analysis:
      - failure_impact_assessment
      - probability_estimation
      - risk_mitigation_strategies
      - contingency_planning
    
    testability_analysis:
      - code_testability_assessment
      - test_data_availability
      - environment_constraints
      - tooling_limitations
  
  test_design:
    design_techniques:
      black_box:
        - equivalence_partitioning
        - boundary_value_analysis
        - decision_table_testing
        - state_transition_testing
      
      white_box:
        - statement_coverage
        - branch_coverage
        - path_coverage
        - condition_coverage
      
      experience_based:
        - error_guessing
        - exploratory_testing
        - checklist_based_testing
    
    test_case_specification:
      structure:
        - test_case_id
        - test_description
        - preconditions
        - test_steps
        - expected_results
        - post_conditions
      
      attributes:
        - priority_level
        - complexity_rating
        - execution_time_estimate
        - required_test_data
        - environment_requirements
  
  resource_planning:
    human_resources:
      roles:
        - test_architect
        - test_engineers
        - automation_engineers
        - performance_testers
        - security_testers
      
      skills_matrix:
        - technical_skills
        - domain_knowledge
        - tool_proficiency
        - certification_status
    
    infrastructure:
      test_environments:
        - development_environment
        - integration_environment
        - staging_environment
        - performance_test_environment
      
      test_data:
        - synthetic_data_generation
        - production_data_masking
        - test_data_management
        - data_refresh_strategies
    
    tools_and_licenses:
      categories:
        - test_management_tools
        - automation_frameworks
        - performance_testing_tools
        - security_testing_tools
        - monitoring_and_reporting_tools

# QUALITY METRICS AND KPIS
metrics:
  test_effectiveness:
    defect_detection_percentage:
      formula: "(Defects found in testing / Total defects) × 100"
      target: "> 85%"
      
    test_coverage:
      code_coverage:
        statement_coverage: "> 80%"
        branch_coverage: "> 75%"
        function_coverage: "> 90%"
      
      requirements_coverage:
        functional_coverage: "100%"
        business_rule_coverage: "100%"
        user_story_coverage: "100%"
  
  test_efficiency:
    automation_rate:
      formula: "(Automated tests / Total tests) × 100"
      target: "> 70%"
    
    test_execution_time:
      unit_tests: "< 5 minutes"
      integration_tests: "< 30 minutes"
      e2e_tests: "< 2 hours"
    
    defect_turnaround_time:
      critical_defects: "< 4 hours"
      high_defects: "< 24 hours"
      medium_defects: "< 72 hours"
  
  process_quality:
    test_case_pass_rate:
      first_execution: "> 85%"
      after_fixes: "> 95%"
    
    test_stability:
      flaky_test_rate: "< 5%"
      false_positive_rate: "< 2%"
    
    release_quality:
      escaped_defects: "< 2 per release"
      production_incidents: "< 1 per month"
      customer_satisfaction: "> 95%"

# TESTING GOVERNANCE
governance:
  testing_standards:
    naming_conventions:
      test_methods: "should_[expected_behavior]_when_[condition]"
      test_classes: "[ClassName]Test"
      test_files: "[module].test.[extension]"
    
    documentation_requirements:
      - test_plan_documentation
      - test_case_specifications
      - automation_framework_documentation
      - test_environment_setup_guides
    
    review_processes:
      test_design_reviews:
        participants: ["test_architect", "developers", "product_owner"]
        criteria: ["coverage_completeness", "risk_alignment", "maintainability"]
      
      automation_code_reviews:
        participants: ["automation_engineers", "developers"]
        criteria: ["code_quality", "maintainability", "reusability"]
  
  quality_gates:
    entry_criteria:
      - requirements_baseline_established
      - test_environment_ready
      - test_data_available
      - testing_team_trained
    
    exit_criteria:
      - planned_test_cases_executed
      - coverage_targets_achieved
      - critical_defects_resolved
      - acceptance_criteria_met
    
    go_no_go_decisions:
      factors:
        - defect_severity_distribution
        - test_coverage_achievement
        - performance_benchmarks
        - security_compliance
        - business_acceptance

# CONTINUOUS IMPROVEMENT
improvement:
  retrospective_process:
    frequency: "After each release"
    participants: ["testing_team", "development_team", "product_team"]
    
    review_areas:
      - testing_effectiveness
      - process_efficiency
      - tool_utilization
      - team_collaboration
    
    outcome_tracking:
      - action_items_definition
      - implementation_timeline
      - success_metrics
      - follow_up_schedule
  
  metrics_driven_improvement:
    data_collection:
      - automated_metrics_gathering
      - manual_observation_logs
      - stakeholder_feedback
      - industry_benchmarking
    
    analysis_techniques:
      - trend_analysis
      - root_cause_analysis
      - comparative_analysis
      - predictive_modeling
    
    improvement_initiatives:
      - process_optimization
      - tool_evaluation_and_adoption
      - skills_development_programs
      - automation_expansion